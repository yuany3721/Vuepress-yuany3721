(window.webpackJsonp=window.webpackJsonp||[]).push([[95],{671:function(e,t,n){"use strict";n.r(t);var a=n(17),o=Object(a.a)({},(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h2",{attrs:{id:"fastapi-docs"}},[e._v("FastAPI docs")]),e._v(" "),n("p",[e._v("由FastAPI自动生成的API"),n("a",{attrs:{href:"http://yuany3721.site:6017/docs",target:"_blank",rel:"noopener noreferrer"}},[e._v("说明页面"),n("OutboundLink")],1),e._v("，由"),n("a",{attrs:{href:"https://github.com/THUDM/ChatGLM3/blob/main/openai_api_demo/api_server.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("API部署代码"),n("OutboundLink")],1),e._v("中注释自动生成，基于"),n("a",{attrs:{href:"https://platform.openai.com/docs/api-reference/chat",target:"_blank",rel:"noopener noreferrer"}},[e._v("OpenAI API"),n("OutboundLink")],1),e._v("。")]),e._v(" "),n("p",[e._v("API入口：")]),e._v(" "),n("ul",[n("li",[e._v('"/health": 响应API运行状态，返回200则运行正常')]),e._v(" "),n("li",[e._v('"/v1/chat/completions": 响应文本对话请求，可选是否流式输出')]),e._v(" "),n("li",[e._v('"/v1/embeddings": 响应一组列表式文本对话请求')])]),e._v(" "),n("p",[e._v("更多代码说明：")]),e._v(" "),n("blockquote",[n("p",[e._v("This script implements an API for the ChatGLM3-6B model,\nformatted similarly to OpenAI's API (https://platform.openai.com/docs/api-reference/chat).\nIt's designed to be run as a web server using FastAPI and uvicorn,\nmaking the ChatGLM3-6B model accessible through OpenAI Client.")]),e._v(" "),n("p",[e._v("Key Components and Features:")]),e._v(" "),n("ul",[n("li",[e._v("Model and Tokenizer Setup: Configures the model and tokenizer paths and loads them.")]),e._v(" "),n("li",[e._v("FastAPI Configuration: Sets up a FastAPI application with CORS middleware for handling cross-origin requests.")]),e._v(" "),n("li",[e._v("API Endpoints:\n"),n("ul",[n("li",[e._v('"/v1/models": Lists the available models, specifically ChatGLM3-6B.')]),e._v(" "),n("li",[e._v('"/v1/chat/completions": Processes chat completion requests with options for streaming and regular responses.')]),e._v(" "),n("li",[e._v('"/v1/embeddings": Processes Embedding request of a list of text inputs.')])])]),e._v(" "),n("li",[e._v("Token Limit Caution: In the OpenAI API, 'max_tokens' is equivalent to HuggingFace's 'max_new_tokens', not 'max_length'.\nFor instance, setting 'max_tokens' to 8192 for a 6b model would result in an error due to the model's inability to output\nthat many tokens after accounting for the history and prompt tokens.")]),e._v(" "),n("li",[e._v("Stream Handling and Custom Functions: Manages streaming responses and custom function calls within chat responses.")]),e._v(" "),n("li",[e._v("Pydantic Models: Defines structured models for requests and responses, enhancing API documentation and type safety.")]),e._v(" "),n("li",[e._v("Main Execution: Initializes the model and tokenizer, and starts the FastAPI app on the designated host and port.")])])]),e._v(" "),n("h2",{attrs:{id:"api调用示例"}},[e._v("API调用示例")]),e._v(" "),n("p",[e._v("参考"),n("a",{attrs:{href:"https://github.com/THUDM/ChatGLM3/blob/main/openai_api_demo/openai_api_request.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("api-demo"),n("OutboundLink")],1)]),e._v(" "),n("p",[e._v("修改第15行"),n("code",[e._v("base_url")]),e._v("为目标URL。")])])}),[],!1,null,null,null);t.default=o.exports}}]);