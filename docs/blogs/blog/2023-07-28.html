<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>开源LLM模型及社区项目调研 | Vuepress-reco-yuany3721</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/favicon.ico">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <meta name="description" content=" ">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.c30ea535.css" as="style"><link rel="preload" href="/assets/js/app.09260907.js" as="script"><link rel="preload" href="/assets/js/4.cca5eb70.js" as="script"><link rel="preload" href="/assets/js/1.f43eb6c5.js" as="script"><link rel="preload" href="/assets/js/16.5a5d6c69.js" as="script"><link rel="prefetch" href="/assets/js/10.24e18764.js"><link rel="prefetch" href="/assets/js/100.6b97092a.js"><link rel="prefetch" href="/assets/js/101.113c0723.js"><link rel="prefetch" href="/assets/js/102.16b18ae7.js"><link rel="prefetch" href="/assets/js/11.4236cc8c.js"><link rel="prefetch" href="/assets/js/12.33d950a1.js"><link rel="prefetch" href="/assets/js/13.9c0d8ff7.js"><link rel="prefetch" href="/assets/js/14.7a082869.js"><link rel="prefetch" href="/assets/js/15.10cb7003.js"><link rel="prefetch" href="/assets/js/17.539ca804.js"><link rel="prefetch" href="/assets/js/18.22d95b39.js"><link rel="prefetch" href="/assets/js/19.b62f911d.js"><link rel="prefetch" href="/assets/js/2.d2df9f30.js"><link rel="prefetch" href="/assets/js/20.3ba6e94f.js"><link rel="prefetch" href="/assets/js/21.4f570ac0.js"><link rel="prefetch" href="/assets/js/22.0c67b2d6.js"><link rel="prefetch" href="/assets/js/23.f769654f.js"><link rel="prefetch" href="/assets/js/24.9da200f4.js"><link rel="prefetch" href="/assets/js/25.2af1a1d3.js"><link rel="prefetch" href="/assets/js/26.8f51fabb.js"><link rel="prefetch" href="/assets/js/27.81f033fb.js"><link rel="prefetch" href="/assets/js/28.ed070557.js"><link rel="prefetch" href="/assets/js/29.38734a5c.js"><link rel="prefetch" href="/assets/js/30.332a6f58.js"><link rel="prefetch" href="/assets/js/31.b9060e35.js"><link rel="prefetch" href="/assets/js/32.bc437a0c.js"><link rel="prefetch" href="/assets/js/33.0a8f6af4.js"><link rel="prefetch" href="/assets/js/34.752dd02f.js"><link rel="prefetch" href="/assets/js/35.2f5ef2cb.js"><link rel="prefetch" href="/assets/js/36.45b1dff7.js"><link rel="prefetch" href="/assets/js/37.1fc2663c.js"><link rel="prefetch" href="/assets/js/38.801e04c5.js"><link rel="prefetch" href="/assets/js/39.8405c7a6.js"><link rel="prefetch" href="/assets/js/40.cc4a6d6d.js"><link rel="prefetch" href="/assets/js/41.41d99cb0.js"><link rel="prefetch" href="/assets/js/42.8532630d.js"><link rel="prefetch" href="/assets/js/43.66c38202.js"><link rel="prefetch" href="/assets/js/44.e2df7979.js"><link rel="prefetch" href="/assets/js/45.8da17893.js"><link rel="prefetch" href="/assets/js/46.41c7bb6d.js"><link rel="prefetch" href="/assets/js/47.dd4b570c.js"><link rel="prefetch" href="/assets/js/48.f54a3ce8.js"><link rel="prefetch" href="/assets/js/49.3364bf00.js"><link rel="prefetch" href="/assets/js/5.e0822530.js"><link rel="prefetch" href="/assets/js/50.0088a417.js"><link rel="prefetch" href="/assets/js/51.c02dd8e6.js"><link rel="prefetch" href="/assets/js/52.8fd27f77.js"><link rel="prefetch" href="/assets/js/53.1fc3d5c0.js"><link rel="prefetch" href="/assets/js/54.20595c72.js"><link rel="prefetch" href="/assets/js/55.686e5820.js"><link rel="prefetch" href="/assets/js/56.fd4ae071.js"><link rel="prefetch" href="/assets/js/57.6c3a5388.js"><link rel="prefetch" href="/assets/js/58.52972732.js"><link rel="prefetch" href="/assets/js/59.20aeec7f.js"><link rel="prefetch" href="/assets/js/6.5764ed17.js"><link rel="prefetch" href="/assets/js/60.9994dc68.js"><link rel="prefetch" href="/assets/js/61.4393f2fa.js"><link rel="prefetch" href="/assets/js/62.c93963ac.js"><link rel="prefetch" href="/assets/js/63.968911bb.js"><link rel="prefetch" href="/assets/js/64.20c0b06c.js"><link rel="prefetch" href="/assets/js/65.f7c9c191.js"><link rel="prefetch" href="/assets/js/66.0506b3b8.js"><link rel="prefetch" href="/assets/js/67.cde14a38.js"><link rel="prefetch" href="/assets/js/68.6ed5c854.js"><link rel="prefetch" href="/assets/js/69.a60dff04.js"><link rel="prefetch" href="/assets/js/7.25635ab6.js"><link rel="prefetch" href="/assets/js/70.9082832c.js"><link rel="prefetch" href="/assets/js/71.76b9788b.js"><link rel="prefetch" href="/assets/js/72.94de2f7c.js"><link rel="prefetch" href="/assets/js/73.47bffa87.js"><link rel="prefetch" href="/assets/js/74.06ce6b0d.js"><link rel="prefetch" href="/assets/js/75.7e32e7a3.js"><link rel="prefetch" href="/assets/js/76.925ade50.js"><link rel="prefetch" href="/assets/js/77.1b18324f.js"><link rel="prefetch" href="/assets/js/78.b43eaf03.js"><link rel="prefetch" href="/assets/js/79.94c8b22a.js"><link rel="prefetch" href="/assets/js/8.f6b18623.js"><link rel="prefetch" href="/assets/js/80.a50744d5.js"><link rel="prefetch" href="/assets/js/81.a4969578.js"><link rel="prefetch" href="/assets/js/82.6d7eeccb.js"><link rel="prefetch" href="/assets/js/83.cc1be3dc.js"><link rel="prefetch" href="/assets/js/84.4a8c6b41.js"><link rel="prefetch" href="/assets/js/85.87777f09.js"><link rel="prefetch" href="/assets/js/86.22efe427.js"><link rel="prefetch" href="/assets/js/87.a10dae5e.js"><link rel="prefetch" href="/assets/js/88.2ada5546.js"><link rel="prefetch" href="/assets/js/89.b7a50910.js"><link rel="prefetch" href="/assets/js/9.9ca8ebdb.js"><link rel="prefetch" href="/assets/js/90.c5596152.js"><link rel="prefetch" href="/assets/js/91.d1c02bf6.js"><link rel="prefetch" href="/assets/js/92.1a20d092.js"><link rel="prefetch" href="/assets/js/93.debaab83.js"><link rel="prefetch" href="/assets/js/94.60051da3.js"><link rel="prefetch" href="/assets/js/95.770b649a.js"><link rel="prefetch" href="/assets/js/96.f4a59ac9.js"><link rel="prefetch" href="/assets/js/97.bb99a1d6.js"><link rel="prefetch" href="/assets/js/98.5e66eab6.js"><link rel="prefetch" href="/assets/js/99.8bb10ac6.js">
    <link rel="stylesheet" href="/assets/css/0.styles.c30ea535.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-2b92a942><div data-v-2b92a942><div class="password-shadow password-wrapper-out" style="display:none;" data-v-24de1186 data-v-2b92a942 data-v-2b92a942><h3 class="title" data-v-24de1186 data-v-24de1186>Vuepress-reco-yuany3721</h3> <p class="description" data-v-24de1186 data-v-24de1186> </p> <label id="box" class="inputBox" data-v-24de1186 data-v-24de1186><input type="password" value="" data-v-24de1186> <span data-v-24de1186>Konck! Knock!</span> <button data-v-24de1186>OK</button></label> <div class="footer" data-v-24de1186 data-v-24de1186><span data-v-24de1186><i class="iconfont reco-theme" data-v-24de1186></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-24de1186>vuePress-theme-reco</a></span> <span data-v-24de1186><i class="iconfont reco-copyright" data-v-24de1186></i> <a data-v-24de1186><span data-v-24de1186>yuany3721</span>
            
          <span data-v-24de1186>2022 - </span>
          2025
        </a></span></div></div> <div class="hide" data-v-2b92a942><header class="navbar" data-v-2b92a942><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="Vuepress-reco-yuany3721" class="logo"> <span class="site-name">Vuepress-reco-yuany3721</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/blog/" class="nav-link"><i class="undefined"></i>
  blog
</a></li><li class="dropdown-item"><!----> <a href="/categories/随记/" class="nav-link"><i class="undefined"></i>
  随记
</a></li><li class="dropdown-item"><!----> <a href="/categories/学习笔记/" class="nav-link"><i class="undefined"></i>
  学习笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/杂谈/" class="nav-link"><i class="undefined"></i>
  杂谈
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-suggestion"></i>
      更新日志
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/updatelog/Web/" class="nav-link"><i class="undefined"></i>
  Web
</a></li><li class="dropdown-item"><!----> <a href="/updatelog/Bot/" class="nav-link"><i class="undefined"></i>
  Bot
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-document"></i>
      API文档
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/readdoc/glm3/" class="nav-link"><i class="undefined"></i>
  GLM3
</a></li><li class="dropdown-item"><!----> <a href="/readdoc/AD9910/" class="nav-link"><i class="undefined"></i>
  AD9910
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-2b92a942></div> <aside class="sidebar" data-v-2b92a942><div class="personal-info-wrapper" data-v-29bd5bbe data-v-2b92a942><img src="/avatar.png" alt="author-avatar" class="personal-img" data-v-29bd5bbe> <h3 class="name" data-v-29bd5bbe>
    yuany3721
  </h3> <div class="num" data-v-29bd5bbe><div data-v-29bd5bbe><h3 data-v-29bd5bbe>91</h3> <h6 data-v-29bd5bbe>文章</h6></div> <div data-v-29bd5bbe><h3 data-v-29bd5bbe>28</h3> <h6 data-v-29bd5bbe>标签</h6></div></div> <ul class="social-links" data-v-29bd5bbe></ul> <hr data-v-29bd5bbe></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  主页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/blog/" class="nav-link"><i class="undefined"></i>
  blog
</a></li><li class="dropdown-item"><!----> <a href="/categories/随记/" class="nav-link"><i class="undefined"></i>
  随记
</a></li><li class="dropdown-item"><!----> <a href="/categories/学习笔记/" class="nav-link"><i class="undefined"></i>
  学习笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/杂谈/" class="nav-link"><i class="undefined"></i>
  杂谈
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-suggestion"></i>
      更新日志
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/updatelog/Web/" class="nav-link"><i class="undefined"></i>
  Web
</a></li><li class="dropdown-item"><!----> <a href="/updatelog/Bot/" class="nav-link"><i class="undefined"></i>
  Bot
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-document"></i>
      API文档
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/readdoc/glm3/" class="nav-link"><i class="undefined"></i>
  GLM3
</a></li><li class="dropdown-item"><!----> <a href="/readdoc/AD9910/" class="nav-link"><i class="undefined"></i>
  AD9910
</a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-24de1186 data-v-2b92a942><h3 class="title" data-v-24de1186 data-v-24de1186>开源LLM模型及社区项目调研</h3> <!----> <label id="box" class="inputBox" data-v-24de1186 data-v-24de1186><input type="password" value="" data-v-24de1186> <span data-v-24de1186>Konck! Knock!</span> <button data-v-24de1186>OK</button></label> <div class="footer" data-v-24de1186 data-v-24de1186><span data-v-24de1186><i class="iconfont reco-theme" data-v-24de1186></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-24de1186>vuePress-theme-reco</a></span> <span data-v-24de1186><i class="iconfont reco-copyright" data-v-24de1186></i> <a data-v-24de1186><span data-v-24de1186>yuany3721</span>
            
          <span data-v-24de1186>2022 - </span>
          2025
        </a></span></div></div> <div data-v-2b92a942><main class="page"><section><div class="page-title"><h1 class="title">开源LLM模型及社区项目调研</h1> <div data-v-6b827e97><i class="iconfont reco-account" data-v-6b827e97><span data-v-6b827e97>yuany3721 danc</span></i> <i class="iconfont reco-date" data-v-6b827e97><span data-v-6b827e97>2023/7/29</span></i> <!----> <i class="tags iconfont reco-tag" data-v-6b827e97><span class="tag-item" data-v-6b827e97>LLM</span></i></div></div> <div class="theme-reco-content content__default"><blockquote><p><strong>注意：</strong></p> <p><strong>该博客内容不对真实性、专业性作出任何保障，仅作记录参考使用，如有错误欢迎联系指正</strong></p> <p><strong>本调研内容截止日期为2023年7月28日，由于LLM的强时效性，您在进行参考时务必确认相关内容是否接近此日期及此日期之后的更新或修改</strong></p></blockquote> <h2 id="引言">引言</h2> <p>近年来，大型语言模型（Large Language Model，LLM）取得了显著的进展。</p> <p>其中，GPT-4作为代表性的语言模型，在文本生成、问答系统和对话生成方面表现出色。然而，由于特定场景对隐私性和准确性的要求，需要寻找一种能够在本地部署大型语言模型并能提供准确回答的解决方案。</p> <p>具体到本次调研，简单列出需求如下：</p> <ol><li><p>在24G显存条件下可以完成项目部署；</p></li> <li><p>可部署的模型对中文有一定支持；</p></li> <li><p>项目提供给用户的答案应当是足够可靠的；</p></li> <li><p>项目要便于部署、维护，有一定的社区生态支持。</p></li></ol> <h2 id="llm规模与gpu需求">LLM规模与GPU需求</h2> <p>通常，大型语言模型（Large Language Model，LLM）的规模会在模型名称中使用类似于<code>7B</code>的关键词，用来表示该模型的参数规模为70亿。一般性地，模型参数越多，模型效果越好，对硬件的需求也越高。</p> <p>在LLM的部署过程中，可以采用模型量化技术对模型参数进行压缩，以降低硬件需求、提升计算速度。常见的量化等级包括<code>FP16</code>、<code>BF16</code>、<code>INT8</code>和<code>INT4</code>，分别代表使用16位浮点数、16位浮点数（Google Brain Floating）、8位整数和4位整数进行近似计算。据不可靠来源，对模型进行量化可能会使模型更容易出现幻觉，因此本次部署中在相似条件下优先选择<code>FP16</code>、<code>BF16</code>精度进行部署。</p> <p>以<a href="https://huggingface.co/THUDM/chatglm2-6b" target="_blank" rel="noopener noreferrer">ChatGLM2-6B<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>为例，在不同的量化等级下所需的最小显存如下：</p> <table><thead><tr><th><strong>量化等级</strong></th> <th><strong>编码 2048 长度的最小显存</strong></th> <th><strong>生成 8192 长度的最小显存</strong></th></tr></thead> <tbody><tr><td>FP16 / BF16</td> <td>13.1 GB</td> <td>12.8 GB</td></tr> <tr><td>INT8</td> <td>8.2 GB</td> <td>8.1 GB</td></tr> <tr><td>INT4</td> <td>5.5 GB</td> <td>5.1 GB</td></tr></tbody></table> <p>一般而言，<code>7B</code>规模的模型以<code>INT4</code>量化需要5G显存，在此基础上参数规模每提高<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span></span></span></span>倍，需要的显存大小变为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.664392em;"></span><span class="strut bottom" style="height:0.664392em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。如果以16位浮点数精度部署模型，24G显存能运行的最大模型为14B左右。</p> <h3 id="量化对模型性能的影响"><strong>量化对模型性能的影响</strong></h3> <p>GLM团队也测试了<a href="https://github.com/THUDM/ChatGLM2-6B#%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD" target="_blank" rel="noopener noreferrer">量化对模型性能的影响<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。结果表明，量化对模型性能的影响在可接受范围内。</p> <table><thead><tr><th>ChatGLM-6B量化等级</th> <th>Accuracy (<a href="https://github.com/hendrycks/test" target="_blank" rel="noopener noreferrer">MMLU<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>)</th> <th>Accuracy (<a href="https://cevalbenchmark.com/static/leaderboard.html" target="_blank" rel="noopener noreferrer">C-Eval dev<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>)</th></tr></thead> <tbody><tr><td>BF16</td> <td>45.47</td> <td>53.57</td></tr> <tr><td>INT4</td> <td>43.13</td> <td>50.30</td></tr></tbody></table> <h2 id="模型选取">模型选取</h2> <p>在模型选取阶段，我们参考了一些国内外各模型测评方案、LLM跟踪榜单，主要包括以下内容：</p> <ol><li><strong>评测集</strong></li></ol> <ul><li><p><a href="https://github.com/hendrycks/test" target="_blank" rel="noopener noreferrer">MMLU<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：一个包含57个多选任务的英文评测数据集，涵盖了初等数学、美国历史、计算机科学、法律等，难度覆盖高中水平到专家水平，在<a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>上提供了<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank" rel="noopener noreferrer">Open LLM Leaderboard<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>测试信息统计。</p></li> <li><p><a href="https://github.com/SJTU-LIT/ceval" target="_blank" rel="noopener noreferrer">C-Eval<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：一个全面的中文基础模型评估套件，涵盖了52个不同学科的13948个多项选择题，在<a href="https://cevalbenchmark.com/index_zh.html" target="_blank" rel="noopener noreferrer">官网<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>提供了<a href="https://cevalbenchmark.com/static/leaderboard_zh.html" target="_blank" rel="noopener noreferrer">C-Eval排行榜<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p></li> <li><p><a href="https://github.com/OpenLMLab/GAOKAO-Bench" target="_blank" rel="noopener noreferrer">Gaokao<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：由复旦大学研究团队构建的基于中国高考题目的综合性考试评测集，包含多科目多题型，并提供了9种模型的评测结果。</p></li> <li><p><a href="https://arxiv.org/pdf/2304.06364.pdf" target="_blank" rel="noopener noreferrer">AGIEval<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：用于评估基础模型在与人类认知和解决问题相关的任务中的一般能力，基于普通大学入学考试、数学竞赛、律师资格考试等20项面向普通考生的官方、公开、高标准的入学和资格考试构建。</p></li> <li><p><a href="https://github.com/haonan-li/CMMLU" target="_blank" rel="noopener noreferrer">CMMLU<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：一个综合性的中文评估基准，专门用于评估语言模型在中文语境下的知识和推理能力，涵盖了从基础学科到高级专业水平的67个主题，提供了14种LLM的评测结果。</p></li> <li><p><a href="https://github.com/michael-wzhu/PromptCBLUE" target="_blank" rel="noopener noreferrer">PromptCBLUE<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：将16种不同的医疗场景NLP任务转化为基于提示的语言生成任务形成的首个中文医疗场景的LLM评测基准，当前在<a href="https://tianchi.aliyun.com/competition/entrance/532084/introduction" target="_blank" rel="noopener noreferrer">阿里巴巴天池大赛平台<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>上线进行开放评测。</p></li></ul> <ol start="2"><li><strong>LLM跟踪榜单</strong></li></ol> <ul><li><p><a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM" target="_blank" rel="noopener noreferrer">An Awesome Collection for LLM in Chinese<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：已收集超过100个中文LLM相关的开源模型、应用、数据集及教程。</p></li> <li><p><a href="https://github.com/jeinlee1991/chinese-llm-benchmark" target="_blank" rel="noopener noreferrer">CLiB中文大模型能力评测榜单（持续更新）<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>:提供分类能力、信息抽取能力、阅读理解能力、表格问答能力等多个维度的大模型评测结果。</p></li> <li><p><a href="https://github.com/chenking2020/FindTheChatGPTer" target="_blank" rel="noopener noreferrer">寻找那些ChatGPT/GPT4开源“平替”们<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>：ChatGPT/GPT4开源“平替”汇总，包括自主模型、Alpaca模式微调模型、AGI项目、榜单、语料等多维度内容。</p></li></ul> <h2 id="相关开源项目对比">相关开源项目对比</h2> <p>基于以上调研，项目的选取范围定为：支持本地知识库的LLM调用项目。</p> <p>初步选取符合要求的项目有三个：<a href="https://github.com/chatchat-space/langchain-ChatGLM" target="_blank" rel="noopener noreferrer">langchain-ChatGLM：基于本地知识库的 ChatGLM 等大语言模型应用实现<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>、<a href="https://github.com/wenda-LLM/wenda" target="_blank" rel="noopener noreferrer">闻达：一个大规模语言模型调用平台<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>、<a href="https://github.com/binary-husky/gpt_academic" target="_blank" rel="noopener noreferrer">gpt_academic：GPT 学术优化<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>模型方面，当前最优LLM模型为<a href="https://github.com/THUDM/ChatGLM2-6B" target="_blank" rel="noopener noreferrer"><code>ChatGLM2-6B</code><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，知识库向量化模型选择<a href="https://huggingface.co/moka-ai/m3e-base" target="_blank" rel="noopener noreferrer"><code>m3e-base</code><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <h3 id="langchain-chatglm"><strong>langchain-ChatGLM</strong></h3> <p>langchain-ChatGLM是一个利用<a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer">langchain<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>思想实现的基于本地知识库的问答应用，目标期望建立一套对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。</p> <p><img src="/assets/img/langchain_chatglm.0dd4abd5.png" alt="langchain-ChatGLM"></p> <p>该项目主要特点包括：</p> <ul><li><p>支持Docker部署，同时提供开发部署方案</p></li> <li><p>支持ChatGLM、ChatYuan等多种模型，支持通过fastchat API调用任意LLM</p></li> <li><p>知识库接入非结构化文档，当前已支持md、pdf、docx、txt格式，支持jpg与png格式图片的OCR文字识别</p></li> <li><p>路线图（未来计划实现的功能）中包含结构化数据（csv、Excel、SQL等）接入、知识图谱/图数据库接入、Agent实现</p></li> <li><p>支持多种知识库Embedding模型</p></li> <li><p>支持搜索引擎问答</p></li></ul> <h3 id="闻达"><strong>闻达</strong></h3> <p>闻达项目的设计目标是实现针对特定环境的高效内容生成，同时考虑个人和中小企业的计算资源局限性，以及知识安全和私密性问题。该项目的主要特点包括：</p> <ul><li><p>支持chatGLM-6B\chatGLM2-6B、chatRWKV、llama系列、openai api等多种模型接入</p></li> <li><p>支持本地离线向量库（rtst）、本地搜索引擎（fess）、在线搜索引擎三种知识库构建模式</p></li> <li><p>特色Auto脚本：通过开发插件形式的JavaScript脚本，为平台附件功能，实现包括但不限于自定义对话流程、访问外部API、在线切换LoRA模型</p></li> <li><p>使用宏调用API的方式接入Word文档</p></li></ul> <p>值得一提的是，由社区成员AlanLee1996贡献的<a href="https://github.com/AlanLee1996/wenda-webui" target="_blank" rel="noopener noreferrer">Wenda-Webui<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>提供了类似ChatPDF的文档对话功能。</p> <h3 id="gpt-academic"><strong>gpt_academic</strong></h3> <p>gpt_academic是为ChatGPT/GLM设计的图形交互界面，特别优化论文阅读/润色/写作体验，模块化设计，主要特点包括：</p> <ul><li><p>支持复旦MOSS、llama、rwkv、newbing、claude、claude2等多种模型接入</p></li> <li><p>支持多种模型混合调用，支持模型异步加载</p></li> <li><p>支持latex格式论文翻译、总结、润色，支持latex公式渲染</p></li> <li><p>支持自定义强大的函数插件，插件支持热更新</p></li> <li><p>丰富的插件库，支持PDF latex论文解析、代码工程解释、批量注释生成等多种功能</p></li></ul></div></section> <footer class="page-edit"><!----> <!----></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-1ab38110><li class="level-2" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#引言" class="sidebar-link reco-side-引言" data-v-1ab38110>引言</a></li><li class="level-2" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#llm规模与gpu需求" class="sidebar-link reco-side-llm规模与gpu需求" data-v-1ab38110>LLM规模与GPU需求</a></li><li class="level-3" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#量化对模型性能的影响" class="sidebar-link reco-side-量化对模型性能的影响" data-v-1ab38110>量化对模型性能的影响</a></li><li class="level-2" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#模型选取" class="sidebar-link reco-side-模型选取" data-v-1ab38110>模型选取</a></li><li class="level-2" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#相关开源项目对比" class="sidebar-link reco-side-相关开源项目对比" data-v-1ab38110>相关开源项目对比</a></li><li class="level-3" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#langchain-chatglm" class="sidebar-link reco-side-langchain-chatglm" data-v-1ab38110>langchain-ChatGLM</a></li><li class="level-3" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#闻达" class="sidebar-link reco-side-闻达" data-v-1ab38110>闻达</a></li><li class="level-3" data-v-1ab38110><a href="/blogs/blog/2023-07-28.html#gpt-academic" class="sidebar-link reco-side-gpt-academic" data-v-1ab38110>gpt_academic</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/assets/js/app.09260907.js" defer></script><script src="/assets/js/4.cca5eb70.js" defer></script><script src="/assets/js/1.f43eb6c5.js" defer></script><script src="/assets/js/16.5a5d6c69.js" defer></script>
  </body>
</html>
